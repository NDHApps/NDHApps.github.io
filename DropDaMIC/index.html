<!DOCTYPE html>
<html>
    <head>
        <title>DropDa MIC</title>
        <meta name="viewport" content="width=device-width,initial-scale=1.0,user-scalable=no">
        <link rel="stylesheet" type="text/css" href="css/materialize.css">
        <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    </head>
    <body class="splash">
        <header>
            <nav class="top-nav">
                <div class="container">
                    <div class="nav-wrapper">
                        <a href="index.html" class="left brand-logo">
                            <div class="nav-item-wrapper">
                                <img class="nav-item" src="logo.png">
                                <div class="nav-item">
                                    DropDa MIC 
                                </div>
                            </div>
                        </a>
                        <a href="#" data-activates="mobile-demo" class="button-collapse"><i class="material-icons">menu</i></a>
                        <ul class="right hide-on-med-and-down">
                            <li><a href="#About">About</a></li>
                            <li><a href="#Method">Method</a></li>
                            <li><a href="#Results">Results</a></li>
                            <li><a href="https://github.com/jasonlustbader/eecs352finalproject">GitHub</a></li>
                        </ul>
                        <ul class="side-nav" id="mobile-demo">
                            <li><a href="index.html">Home</a></li>
                            <li><a href="#About">About</a></li>
                            <li><a href="#Method">Method</a></li>
                            <li><a href="#Results">Results</a></li>
                            <li><a href="https://github.com/jasonlustbader/eecs352finalproject">GitHub</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </header>
        <div class="main container">
            <div class="left">
                <div class="section">
                    <h4 class="header deep-purple-text">DropDa MIC (Musical Instrument Classifier)</h4>
                    <h6>Final Project for EECS 352: Machine Perception of Music and Audio</h6>
                    <h6>Northwestern University</h6>
                    <h6>Professor Bryan Pardo</h6>
                    <div class="row">
                        <div class="col s12 m6 l4">
                            <h5>Hannah Arntson</h5>
                            <h6 class="truncate">HannahArntson2016@u.northwestern.edu</h6>
                        </div>
                        <div class="col s12 m6 l4">
                            <h5>Nicholas Hall</h5>
                            <h6 class="truncate">NicholasHall2016@u.northwestern.edu</h6>
                        </div>
                        <div class="col s12 m6 l4">
                            <h5>Jason Lustbader</h5>
                            <h6 class="truncate">JasonLustbader2016@u.northwestern.edu</h6>
                        </div>
                    </div>
                </div>
                <div class="divider"></div>
                <div class="section" id="About">
                    <h4 class="deep-purple-text">About</h4>
                    <div class="flow-text">
                        DropDa Mic is a musical instrument classification system that can identify a musical instrument from a short sample of that instrument playing. Our team identified common musical instruments used in classical music recordings and compiled a library of many short samples for each of these selected instruments. We then chose specific features for each sample that we thought would be relevant based on what we learned in the class and used a K-Nearest Neighbors algorithm (KNN) to classify samples.
                    </div>
                    <h5>Motivation</h5>
                    <div class="flow-text">
                        We are all very musical and can easily tell the difference between different instruments and groupings of instruments. We thought it would be interesting to teach a computer to make the same differentiations.
                        <br><br>
                    </div>
                </div>
                <div class="divider"></div>
                <div class="section" id="Method">
                    <h4 class="deep-purple-text">Method</h4>
                    <div class="flow-text">
                        We used musical instrument samples from the <a href="http://theremin.music.uiowa.edu/MIS.html">University of Iowa Musical Instrument Samples (MIS)</a> dataset. We picked five (5) very different sounding instruments to put into our database: flute, bass clarinet, french horn, violin, and double bass. We loaded several short 2-3 second .wav samples of each using Librosa and then used the middle-most second of each audio file to account for silence at the beginning and end of notes. From there, we divided each audio sample into 2048 sample frames. For each sample, we calculated discrete Fourier transform (DFT) magnitudes, mel-frequency cepstral coefficients (MFCCs), and energy changes from frame to frame and recorded them along with the label (the instrument) in a hash table so we wouldn't have to recalculate every time we called the classifier. Next, we created a K-nearest neighbor classifier using <a href="http://scikit-learn.org/stable/">scikit-learn</a>. When a new input file is given, we would (like the other files) load it in with Librosa, crop it, divide it into frames and calculate the features- for each frame, we would calculate the minimum euclidean distance from the input feature space to each sample frame in our hash table's feature space. After all the frames had been tested, the instrument with the largest number of frames that were labelled as nearest-neighbor were said to be the algorithm's "guess."
                        <br><br>
                    </div>
                    <h5 class="center">Process Diagram</h5>
                    <img src="1.jpg" class="responsive-img center-block">
                    <br><br>
                    <h5 class="center">Sample</h5>
                    <img src="2.jpg" class="responsive-img center-block">
                    <img src="3.jpg" class="responsive-img center-block">
                    <img src="4.jpg" class="responsive-img center-block">
                    <br><br>
                </div>
                <div class="divider"></div>
                <div class="section" id="Results">
                    <h4 class="deep-purple-text">Results</h4>
                    <div class="flow-text">
                        When we compared two very different instruments--we started with a flute and a trumpet--our classifier was very accurate. However, when we used a full training set that contained 5 instruments (flute, bass clarinet, french horn, violin, and double bass), with 44-104 distinct samples of each instrument over a wide range of notes, we found some interesting results.
                        <br><br>  
                        Almost all of our recordings ended up being labeled as stringed instruments, either violin or double bass. A few were labeled as flutes, and not one recording was labeled as a bass clarinet or french horn, despite running 46 and 44 samples, respectively, of each instrument through the classifier. We are unsure of why the classifier ended up being heavily weighted in favor or stringed instruments. However, we did notice that each instrument's lowest pitched recordings tended to get classified as double bass, while the higher recordings were labeled as violin. This trend was noticeable across the actual violin and double bass recordings as well.
                        <br><br>  
                        To further improve our classifier, we would spend more time experimenting with feature weights.
                        <br><br>
                    </div>
                    <h5 class="center">Confusion Matrix</h5>
                    <img src="5.jpg" class="responsive-img center-block">
                    <br><br>
                </div>
            </div>
        </div>
        <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
        <script type="text/javascript" src="js/index.js"></script>
        <script type="text/javascript" src="js/materialize.min.js"></script>
    </body>
</html>